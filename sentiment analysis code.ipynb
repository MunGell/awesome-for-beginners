{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the Text reviews to numeric values using Document embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               review  sentiment\n",
      "0   Based on an actual story, John Boorman shows t...          1\n",
      "1   This is a gem. As a Film Four production - the...          1\n",
      "2   I really like this show. It has drama, romance...          1\n",
      "3   This is the best 3-D experience Disney has at ...          1\n",
      "4   Of the Korean movies I've seen, only three had...          1\n",
      "5   this movie is funny funny funny my favorite qu...          1\n",
      "6   I'm just starting to explore the so far wonder...          1\n",
      "7   There is no need for me to repeat the synopsis...          1\n",
      "8   I got this movie with my BBC \"Jane Austen Coll...          1\n",
      "9   This was a great movie, I would compare it to ...          1\n",
      "10  I absolutely fell in love with this girls. let...          1\n",
      "11  It started off weird, the middle was weird, an...          1\n",
      "12  If you like silly comedies like Airplane you'l...          1\n",
      "13  The Italian Job requires daylight hours and no...          1\n",
      "14  I watch a lot of movies - DVD, features, and c...          1\n",
      "15  In the future, a disparate group of people asl...          1\n",
      "16  I am really amazed how little fame this film h...          1\n",
      "17  \"Tale of Two Sisters\" has to be one of the cre...          1\n",
      "18  Assy McGee is a show that you really have to b...          1\n",
      "19  This is a great horror movie. Great Plot. And ...          1\n",
      "20  When I first saw the Premiere Episode of Farsc...          1\n",
      "21  There were a lot of dumb teenage getting sex m...          1\n",
      "22  Damien O'Donnell has a good track record and i...          1\n",
      "23  THE ENGLISH PATIENT not only has it all (doome...          1\n",
      "24  cool flick. enjoyable to watch. hope to see mo...          1\n",
      "25  The movie was very good. I'm an avid mystery f...          1\n",
      "26  I have just finished watching this film for th...          1\n",
      "27  This movie from what I remember was such a gre...          1\n",
      "28  The movie takes place during the year 1940 and...          1\n",
      "29  The Cure is a fantastic film about a boy with ...          1\n",
      "..                                                ...        ...\n",
      "70  OK, so this is a complete rip off of the first...          1\n",
      "71  This show is verging on brilliant. It's a mode...          1\n",
      "72  I enjoyed this film and after it finished it s...          1\n",
      "73  Talk Radio sees a man somewhat accidentally st...          1\n",
      "74  We start all of our reviews with the following...          1\n",
      "75  I was extremely amused to read some of the bad...          1\n",
      "76  To experience Head you really need to understa...          1\n",
      "77  I've never seen a movie get a worse release th...          1\n",
      "78  I rented this obscure aussie relic a few years...          1\n",
      "79  \"Four Daughters\" introduced John Garfield to a...          1\n",
      "80  I always liked listening to Buddy Holly and fe...          1\n",
      "81  I was really surprised when I came across this...          1\n",
      "82  This little short absolutely fascinates me.<br...          1\n",
      "83  it's a great movie for the whole family. i don...          1\n",
      "84  i was like watching it right and i was all lik...          1\n",
      "85  The retelling of a classic story is set to the...          1\n",
      "86  This is a great movie. Too bad it is not avail...          1\n",
      "87  Just watched it then. It is pretty damn awesom...          1\n",
      "88  I do not think that this movie deserves the lo...          1\n",
      "89  As a dedicated lover of all things Egyptian th...          1\n",
      "90  I don't understand where these bad comments ar...          1\n",
      "91  this moving was intriguing and absorbing; howe...          1\n",
      "92  I really wanted to be able to give this film a...          1\n",
      "93  I first saw this film accidentally when they s...          1\n",
      "94  An opera diva has an accident, which leaves th...          1\n",
      "95  ***SPOILERS*** ***SPOILERS*** THE CELL / (2000...          1\n",
      "96  It is a very great film (documentary) about Is...          1\n",
      "97  Todd Sheets has created one of the greatest LO...          1\n",
      "98  I have never read the book, but had always hea...          1\n",
      "99  Dolelemite (1975) is a cult classic. Starring ...          1\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://spotleai.sgp1.digitaloceanspaces.com/course/data/movie_review_data.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               review  sentiment\n",
      "0   Based on an actual story, John Boorman shows t...          1\n",
      "1   This is a gem. As a Film Four production - the...          1\n",
      "2   I really like this show. It has drama, romance...          1\n",
      "3   This is the best 3-D experience Disney has at ...          1\n",
      "4   Of the Korean movies I've seen, only three had...          1\n",
      "5   this movie is funny funny funny my favorite qu...          1\n",
      "6   I'm just starting to explore the so far wonder...          1\n",
      "7   There is no need for me to repeat the synopsis...          1\n",
      "8   I got this movie with my BBC \"Jane Austen Coll...          1\n",
      "9   This was a great movie, I would compare it to ...          1\n",
      "10  I absolutely fell in love with this girls. let...          1\n",
      "11  It started off weird, the middle was weird, an...          1\n",
      "12  If you like silly comedies like Airplane you'l...          1\n",
      "13  The Italian Job requires daylight hours and no...          1\n",
      "14  I watch a lot of movies - DVD, features, and c...          1\n",
      "15  In the future, a disparate group of people asl...          1\n",
      "16  I am really amazed how little fame this film h...          1\n",
      "17  \"Tale of Two Sisters\" has to be one of the cre...          1\n",
      "18  Assy McGee is a show that you really have to b...          1\n",
      "19  This is a great horror movie. Great Plot. And ...          1\n",
      "20  When I first saw the Premiere Episode of Farsc...          1\n",
      "21  There were a lot of dumb teenage getting sex m...          1\n",
      "22  Damien O'Donnell has a good track record and i...          1\n",
      "23  THE ENGLISH PATIENT not only has it all (doome...          1\n",
      "24  cool flick. enjoyable to watch. hope to see mo...          1\n",
      "25  The movie was very good. I'm an avid mystery f...          1\n",
      "26  I have just finished watching this film for th...          1\n",
      "27  This movie from what I remember was such a gre...          1\n",
      "28  The movie takes place during the year 1940 and...          1\n",
      "29  The Cure is a fantastic film about a boy with ...          1\n",
      "..                                                ...        ...\n",
      "70  OK, so this is a complete rip off of the first...          1\n",
      "71  This show is verging on brilliant. It's a mode...          1\n",
      "72  I enjoyed this film and after it finished it s...          1\n",
      "73  Talk Radio sees a man somewhat accidentally st...          1\n",
      "74  We start all of our reviews with the following...          1\n",
      "75  I was extremely amused to read some of the bad...          1\n",
      "76  To experience Head you really need to understa...          1\n",
      "77  I've never seen a movie get a worse release th...          1\n",
      "78  I rented this obscure aussie relic a few years...          1\n",
      "79  \"Four Daughters\" introduced John Garfield to a...          1\n",
      "80  I always liked listening to Buddy Holly and fe...          1\n",
      "81  I was really surprised when I came across this...          1\n",
      "82  This little short absolutely fascinates me.<br...          1\n",
      "83  it's a great movie for the whole family. i don...          1\n",
      "84  i was like watching it right and i was all lik...          1\n",
      "85  The retelling of a classic story is set to the...          1\n",
      "86  This is a great movie. Too bad it is not avail...          1\n",
      "87  Just watched it then. It is pretty damn awesom...          1\n",
      "88  I do not think that this movie deserves the lo...          1\n",
      "89  As a dedicated lover of all things Egyptian th...          1\n",
      "90  I don't understand where these bad comments ar...          1\n",
      "91  this moving was intriguing and absorbing; howe...          1\n",
      "92  I really wanted to be able to give this film a...          1\n",
      "93  I first saw this film accidentally when they s...          1\n",
      "94  An opera diva has an accident, which leaves th...          1\n",
      "95  ***SPOILERS*** ***SPOILERS*** THE CELL / (2000...          1\n",
      "96  It is a very great film (documentary) about Is...          1\n",
      "97  Todd Sheets has created one of the greatest LO...          1\n",
      "98  I have never read the book, but had always hea...          1\n",
      "99  Dolelemite (1975) is a cult classic. Starring ...          1\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = list(df.loc[:25000, 'review'].values)\n",
    "X_test = list(df.loc[25001:, 'review'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(X_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 50\n",
    "vec_size = 100\n",
    "alpha = 0.025\n",
    "\n",
    "model = Doc2Vec(vector_size=vec_size,\n",
    "        alpha=alpha, \n",
    "        min_alpha=0.00025,\n",
    "        min_count=1,\n",
    "        dm =1)\n",
    "  \n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "  model.train(tagged_data,\n",
    "        total_examples=model.corpus_count,\n",
    "        epochs=model.epochs)\n",
    "  model.alpha -= 0.0002\n",
    "  model.min_alpha = model.alpha\n",
    "\n",
    "model.save(\"doc.vec\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Doc2Vec.load(\"doc.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "narr = np.append([], [])\n",
    "for text in X_train:\n",
    "  txt = word_tokenize(text.lower())\n",
    "  vect = model.infer_vector(txt)\n",
    "  narr = np.append(narr, vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 100)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for text in X_test:\n",
    "  txt = word_tokenize(text.lower())\n",
    "  vect = model.infer_vector(txt)\n",
    "  narr = np.append(narr, vect)\n",
    "narr = np.resize(narr, (50000, vec_size))\n",
    "narr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>col_10</th>\n",
       "      <th>...</th>\n",
       "      <th>col_92</th>\n",
       "      <th>col_93</th>\n",
       "      <th>col_94</th>\n",
       "      <th>col_95</th>\n",
       "      <th>col_96</th>\n",
       "      <th>col_97</th>\n",
       "      <th>col_98</th>\n",
       "      <th>col_99</th>\n",
       "      <th>col_100</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>0.202095</td>\n",
       "      <td>0.537234</td>\n",
       "      <td>-1.088663</td>\n",
       "      <td>-0.525027</td>\n",
       "      <td>0.248526</td>\n",
       "      <td>-0.261927</td>\n",
       "      <td>-0.196288</td>\n",
       "      <td>0.268774</td>\n",
       "      <td>0.371920</td>\n",
       "      <td>-0.008234</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.462995</td>\n",
       "      <td>-0.002993</td>\n",
       "      <td>-0.633289</td>\n",
       "      <td>0.768510</td>\n",
       "      <td>0.038059</td>\n",
       "      <td>0.278316</td>\n",
       "      <td>-0.195076</td>\n",
       "      <td>0.173932</td>\n",
       "      <td>-0.299198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>-0.233895</td>\n",
       "      <td>-0.109597</td>\n",
       "      <td>-0.701388</td>\n",
       "      <td>0.007983</td>\n",
       "      <td>0.742177</td>\n",
       "      <td>-0.513126</td>\n",
       "      <td>-0.523896</td>\n",
       "      <td>0.236320</td>\n",
       "      <td>0.447604</td>\n",
       "      <td>-0.190016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.438865</td>\n",
       "      <td>-0.530374</td>\n",
       "      <td>-0.028351</td>\n",
       "      <td>0.483884</td>\n",
       "      <td>-0.445169</td>\n",
       "      <td>-0.130790</td>\n",
       "      <td>-0.480975</td>\n",
       "      <td>-0.397844</td>\n",
       "      <td>-0.108381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>0.397097</td>\n",
       "      <td>0.799458</td>\n",
       "      <td>-1.116067</td>\n",
       "      <td>0.564277</td>\n",
       "      <td>1.447332</td>\n",
       "      <td>-0.513052</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>-0.071688</td>\n",
       "      <td>0.551531</td>\n",
       "      <td>0.918141</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193167</td>\n",
       "      <td>-0.307577</td>\n",
       "      <td>-0.473804</td>\n",
       "      <td>0.491824</td>\n",
       "      <td>-0.391194</td>\n",
       "      <td>-0.142803</td>\n",
       "      <td>0.101859</td>\n",
       "      <td>0.214777</td>\n",
       "      <td>0.182484</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>-0.110396</td>\n",
       "      <td>0.391524</td>\n",
       "      <td>-0.196285</td>\n",
       "      <td>-0.352988</td>\n",
       "      <td>0.760605</td>\n",
       "      <td>-0.506514</td>\n",
       "      <td>-0.614894</td>\n",
       "      <td>0.178324</td>\n",
       "      <td>0.361245</td>\n",
       "      <td>0.483047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038585</td>\n",
       "      <td>-0.218119</td>\n",
       "      <td>0.162602</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>-0.256859</td>\n",
       "      <td>-0.010412</td>\n",
       "      <td>-0.475135</td>\n",
       "      <td>-0.093340</td>\n",
       "      <td>-0.195824</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>0.245743</td>\n",
       "      <td>-0.094019</td>\n",
       "      <td>-0.383576</td>\n",
       "      <td>-0.839952</td>\n",
       "      <td>0.926735</td>\n",
       "      <td>-0.441442</td>\n",
       "      <td>-1.484607</td>\n",
       "      <td>0.394144</td>\n",
       "      <td>-0.510404</td>\n",
       "      <td>0.469206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379560</td>\n",
       "      <td>-0.358242</td>\n",
       "      <td>-0.665567</td>\n",
       "      <td>0.980332</td>\n",
       "      <td>-0.770728</td>\n",
       "      <td>-1.566290</td>\n",
       "      <td>-1.366231</td>\n",
       "      <td>-0.759360</td>\n",
       "      <td>0.090646</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          col_1     col_2     col_3     col_4     col_5     col_6     col_7  \\\n",
       "49995  0.202095  0.537234 -1.088663 -0.525027  0.248526 -0.261927 -0.196288   \n",
       "49996 -0.233895 -0.109597 -0.701388  0.007983  0.742177 -0.513126 -0.523896   \n",
       "49997  0.397097  0.799458 -1.116067  0.564277  1.447332 -0.513052  0.187500   \n",
       "49998 -0.110396  0.391524 -0.196285 -0.352988  0.760605 -0.506514 -0.614894   \n",
       "49999  0.245743 -0.094019 -0.383576 -0.839952  0.926735 -0.441442 -1.484607   \n",
       "\n",
       "          col_8     col_9    col_10  ...    col_92    col_93    col_94  \\\n",
       "49995  0.268774  0.371920 -0.008234  ... -0.462995 -0.002993 -0.633289   \n",
       "49996  0.236320  0.447604 -0.190016  ... -0.438865 -0.530374 -0.028351   \n",
       "49997 -0.071688  0.551531  0.918141  ... -0.193167 -0.307577 -0.473804   \n",
       "49998  0.178324  0.361245  0.483047  ...  0.038585 -0.218119  0.162602   \n",
       "49999  0.394144 -0.510404  0.469206  ...  0.379560 -0.358242 -0.665567   \n",
       "\n",
       "         col_95    col_96    col_97    col_98    col_99   col_100  sentiment  \n",
       "49995  0.768510  0.038059  0.278316 -0.195076  0.173932 -0.299198          0  \n",
       "49996  0.483884 -0.445169 -0.130790 -0.480975 -0.397844 -0.108381          0  \n",
       "49997  0.491824 -0.391194 -0.142803  0.101859  0.214777  0.182484          0  \n",
       "49998 -0.000078 -0.256859 -0.010412 -0.475135 -0.093340 -0.195824          0  \n",
       "49999  0.980332 -0.770728 -1.566290 -1.366231 -0.759360  0.090646          0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trans = pd.DataFrame(narr, columns=['col_'+ str(i+1) for i in range(narr.shape[1])])\n",
    "df_trans['sentiment'] = df['sentiment']\n",
    "df_trans.to_csv('review_doc2_vectors.csv')\n",
    "df_trans.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Embeddings followed by Decision Tree Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"review_doc2_vectors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df1.pop('sentiment')\n",
    "X = df1.values\n",
    "X_train = df1.loc[:25000].values\n",
    "X_test = df1.loc[25001:].values\n",
    "y_train = y.loc[:25000:].values\n",
    "y_test = y.loc[25001:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "\n",
    "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "      max_features=None, max_leaf_nodes=None,\n",
    "      min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "      min_samples_leaf=1, min_samples_split=2,\n",
    "      min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "      splitter='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model with test dataset:  50.0\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(X_test)\n",
    "acc = round(accuracy_score(y_test, predicted)*100,2)\n",
    "print(\"Accuracy of the model with test dataset: \", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
